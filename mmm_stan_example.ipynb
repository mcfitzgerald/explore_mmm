{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stan\n",
    "import arviz as av\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import mmm_helpers as helpers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Data    \n",
    "# Four years' (209 weeks) records of sales, media impression and media spending at weekly level.   \n",
    "df = pd.read_csv('data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 1. media variables\n",
    "# media impression\n",
    "mdip_cols=[col for col in df.columns if 'mdip_' in col]\n",
    "# media spending\n",
    "mdsp_cols=[col for col in df.columns if 'mdsp_' in col]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 2. control variables\n",
    "# macro economics variables\n",
    "me_cols = [col for col in df.columns if 'me_' in col]\n",
    "# store count variables\n",
    "st_cols = ['st_ct']\n",
    "# markdown/discount variables\n",
    "mrkdn_cols = [col for col in df.columns if 'mrkdn_' in col]\n",
    "# holiday variables\n",
    "hldy_cols = [col for col in df.columns if 'hldy_' in col]\n",
    "# seasonality variables\n",
    "seas_cols = [col for col in df.columns if 'seas_' in col]\n",
    "base_vars = me_cols+st_cols+mrkdn_cols+hldy_cols+seas_cols"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 3. sales variables\n",
    "sales_cols =['sales']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df_ctrl, sc_ctrl = helpers.mean_center_transform(df, ['sales']+me_cols+st_cols+mrkdn_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df_ctrl = pd.concat([df_ctrl, df[hldy_cols+seas_cols]], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# variables positively related to sales: macro economy, store count, markdown, holiday\n",
    "pos_vars = [col for col in base_vars if col not in seas_cols]\n",
    "# using tolist ensures we can json serialize\n",
    "X1 = df_ctrl[pos_vars].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# variables may have either positive or negtive impact on sales: seasonality\n",
    "pn_vars = seas_cols\n",
    "# using tolist ensures we can json serialize\n",
    "X2 = df_ctrl[pn_vars].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "ctrl_data = {\n",
    "    'N': len(df_ctrl),\n",
    "    'K1': len(pos_vars), \n",
    "    'K2': len(pn_vars), \n",
    "    'X1': X1,\n",
    "    'X2': X2, \n",
    "    'y': df_ctrl['sales'].values,\n",
    "    'max_intercept': min(df_ctrl['sales'])\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "ctrl_code = '''\n",
    "data {\n",
    "  int N; // number of observations\n",
    "  int K1; // number of positive predictors\n",
    "  int K2; // number of positive/negative predictors\n",
    "  real max_intercept; // restrict the intercept to be less than the minimum y\n",
    "  matrix[N, K1] X1;\n",
    "  matrix[N, K2] X2;\n",
    "  vector[N] y; \n",
    "}\n",
    "\n",
    "parameters {\n",
    "  vector<lower=0>[K1] beta1; // regression coefficients for X1 (positive)\n",
    "  vector[K2] beta2; // regression coefficients for X2\n",
    "  real<lower=0, upper=max_intercept> alpha; // intercept\n",
    "  real<lower=0> noise_var; // residual variance\n",
    "}\n",
    "\n",
    "model {\n",
    "  // Define the priors\n",
    "  beta1 ~ normal(0, 5); \n",
    "  beta2 ~ normal(0, 5); \n",
    "  noise_var ~ inv_gamma(0.05, 0.05 * 0.01);\n",
    "  // The likelihood\n",
    "  y ~ normal(X1*beta1 + X2*beta2 + alpha, sqrt(noise_var));\n",
    "}\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "ctrl_posterior = stan.build(ctrl_code,data=ctrl_data,random_seed=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_2fnes910/model_hc3fglfm.stan', line 23, column 30: Argument 0.0005 suggests there may be parameters that are not unit scale; consider rescaling with a multiplier (see manual section 22.12).\n",
      "Warning in '/tmp/httpstan_2fnes910/model_hc3fglfm.stan', line 23, column 24: Argument 0.05 suggests there may be parameters that are not unit scale; consider rescaling with a multiplier (see manual section 22.12).\n",
      "Warning: The parameter alpha has no priors.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "ctrl_fit = ctrl_posterior.sample(num_chains=4, num_samples=1000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Sampling:   0%\n",
      "Sampling:   0% (1/8000)\n",
      "Sampling:   0% (2/8000)\n",
      "Sampling:   0% (3/8000)\n",
      "Sampling:   0% (4/8000)\n",
      "Sampling:   1% (103/8000)\n",
      "Sampling:   3% (202/8000)\n",
      "Sampling:   4% (301/8000)\n",
      "Sampling:   5% (400/8000)\n",
      "Sampling:   6% (500/8000)\n",
      "Sampling:   8% (600/8000)\n",
      "Sampling:   9% (700/8000)\n",
      "Sampling:  10% (800/8000)\n",
      "Sampling:  11% (900/8000)\n",
      "Sampling:  12% (1000/8000)\n",
      "Sampling:  14% (1100/8000)\n",
      "Sampling:  15% (1200/8000)\n",
      "Sampling:  16% (1300/8000)\n",
      "Sampling:  18% (1400/8000)\n",
      "Sampling:  19% (1500/8000)\n",
      "Sampling:  20% (1600/8000)\n",
      "Sampling:  21% (1700/8000)\n",
      "Sampling:  22% (1800/8000)\n",
      "Sampling:  24% (1900/8000)\n",
      "Sampling:  25% (2000/8000)\n",
      "Sampling:  26% (2100/8000)\n",
      "Sampling:  28% (2200/8000)\n",
      "Sampling:  29% (2300/8000)\n",
      "Sampling:  30% (2400/8000)\n",
      "Sampling:  31% (2500/8000)\n",
      "Sampling:  32% (2600/8000)\n",
      "Sampling:  34% (2700/8000)\n",
      "Sampling:  35% (2800/8000)\n",
      "Sampling:  36% (2900/8000)\n",
      "Sampling:  38% (3000/8000)\n",
      "Sampling:  39% (3100/8000)\n",
      "Sampling:  40% (3200/8000)\n",
      "Sampling:  41% (3300/8000)\n",
      "Sampling:  42% (3400/8000)\n",
      "Sampling:  44% (3500/8000)\n",
      "Sampling:  45% (3600/8000)\n",
      "Sampling:  46% (3701/8000)\n",
      "Sampling:  49% (3901/8000)\n",
      "Sampling:  53% (4201/8000)\n",
      "Sampling:  58% (4601/8000)\n",
      "Sampling:  61% (4900/8000)\n",
      "Sampling:  66% (5300/8000)\n",
      "Sampling:  76% (6100/8000)\n",
      "Sampling:  85% (6800/8000)\n",
      "Sampling:  94% (7500/8000)\n",
      "Sampling:  96% (7700/8000)\n",
      "Sampling:  99% (7900/8000)\n",
      "Sampling: 100% (8000/8000)\n",
      "Sampling: 100% (8000/8000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 9.8e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.98 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 0.000171 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 1.71 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def extract_ctrl_model(fit_result, pos_vars=pos_vars, pn_vars=pn_vars, \n",
    "                       extract_param_list=False):\n",
    "    ctrl_model = {}\n",
    "    ctrl_model['pos_vars'] = pos_vars\n",
    "    ctrl_model['pn_vars'] = pn_vars\n",
    "    ctrl_model['beta1'] = fit_result['beta1'].mean(axis=1).tolist()\n",
    "    ctrl_model['beta2'] = fit_result['beta2'].mean(axis=1).tolist()\n",
    "    ctrl_model['alpha'] = fit_result['alpha'].mean()\n",
    "    if extract_param_list:\n",
    "        ctrl_model['beta1_list'] = fit_result['beta1'].tolist()\n",
    "        ctrl_model['beta2_list'] = fit_result['beta2'].tolist()\n",
    "        ctrl_model['alpha_list'] = fit_result['alpha'].tolist()\n",
    "    return ctrl_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "base_sales_model = extract_ctrl_model(ctrl_fit, pos_vars=pos_vars, pn_vars=pn_vars)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def ctrl_model_predict(ctrl_model, df):\n",
    "    pos_vars, pn_vars = ctrl_model['pos_vars'], ctrl_model['pn_vars'] \n",
    "    X1, X2 = df[pos_vars].values, df[pn_vars].values\n",
    "    beta1, beta2 = np.array(ctrl_model['beta1']), np.array(ctrl_model['beta2'])\n",
    "    alpha = ctrl_model['alpha']\n",
    "    y_pred = np.dot(X1,beta1) + np.dot(X2,beta2) + alpha\n",
    "    return y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "base_sales = ctrl_model_predict(base_sales_model, df_ctrl)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "df['base_sales'] = base_sales*sc_ctrl['sales']\n",
    "# evaluate control model\n",
    "print('mape: ',helpers.mean_absolute_percentage_error(df['sales'], df['base_sales']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mape:  26.165350389170634\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# 2.2 Marketing Mix Model\n",
    "df_mmm, sc_mmm = helpers.mean_log1p_transform(df, ['sales', 'base_sales'])\n",
    "mu_mdip = df[mdip_cols].apply(np.mean, axis=0).values\n",
    "max_lag = 8\n",
    "num_media = len(mdip_cols)\n",
    "# padding zero * (max_lag-1) rows\n",
    "X_media = np.concatenate((np.zeros((max_lag-1, num_media)), df[mdip_cols].values), axis=0)\n",
    "X_ctrl = df_mmm['base_sales'].values.reshape(len(df),1)\n",
    "mmm_data = {\n",
    "    'N': len(df),\n",
    "    'max_lag': max_lag, \n",
    "    'num_media': num_media,\n",
    "    'X_media': X_media, \n",
    "    'mu_mdip': mu_mdip,\n",
    "    'num_ctrl': X_ctrl.shape[1],\n",
    "    'X_ctrl': X_ctrl, \n",
    "    'y': df_mmm['sales'].values\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "mmm_code = '''\n",
    "functions {\n",
    "  // the adstock transformation with a vector of weights\n",
    "  real Adstock(vector t, row_vector weights) {\n",
    "    return dot_product(t, weights) / sum(weights);\n",
    "  }\n",
    "}\n",
    "data {\n",
    "  // the total number of observations\n",
    "  int<lower=1> N;\n",
    "  // the vector of sales\n",
    "  real y[N];\n",
    "  // the maximum duration of lag effect, in weeks\n",
    "  int<lower=1> max_lag;\n",
    "  // the number of media channels\n",
    "  int<lower=1> num_media;\n",
    "  // matrix of media variables\n",
    "  matrix[N+max_lag-1, num_media] X_media;\n",
    "  // vector of media variables' mean\n",
    "  real mu_mdip[num_media];\n",
    "  // the number of other control variables\n",
    "  int<lower=1> num_ctrl;\n",
    "  // a matrix of control variables\n",
    "  matrix[N, num_ctrl] X_ctrl;\n",
    "}\n",
    "parameters {\n",
    "  // residual variance\n",
    "  real<lower=0> noise_var;\n",
    "  // the intercept\n",
    "  real tau;\n",
    "  // the coefficients for media variables and base sales\n",
    "  vector<lower=0>[num_media+num_ctrl] beta;\n",
    "  // the decay and peak parameter for the adstock transformation of\n",
    "  // each media\n",
    "  vector<lower=0,upper=1>[num_media] decay;\n",
    "  vector<lower=0,upper=ceil(max_lag/2.0)>[num_media] peak;\n",
    "}\n",
    "transformed parameters {\n",
    "  // the cumulative media effect after adstock\n",
    "  real cum_effect;\n",
    "  // matrix of media variables after adstock\n",
    "  matrix[N, num_media] X_media_adstocked;\n",
    "  // matrix of all predictors\n",
    "  matrix[N, num_media+num_ctrl] X;\n",
    "  \n",
    "  // adstock, mean-center, log1p transformation\n",
    "  row_vector[max_lag] lag_weights;\n",
    "  for (nn in 1:N) {\n",
    "    for (media in 1 : num_media) {\n",
    "      for (lag in 1 : max_lag) {\n",
    "        lag_weights[max_lag-lag+1] <- pow(decay[media], (lag - 1 - peak[media]) ^ 2);\n",
    "      }\n",
    "     cum_effect <- Adstock(sub_col(X_media, nn, media, max_lag), lag_weights);\n",
    "     X_media_adstocked[nn, media] <- log1p(cum_effect/mu_mdip[media]);\n",
    "    }\n",
    "  X <- append_col(X_media_adstocked, X_ctrl);\n",
    "  } \n",
    "}\n",
    "model {\n",
    "  decay ~ beta(3,3);\n",
    "  peak ~ uniform(0, ceil(max_lag/2.0));\n",
    "  tau ~ normal(0, 5);\n",
    "  for (i in 1 : num_media+num_ctrl) {\n",
    "    beta[i] ~ normal(0, 1);\n",
    "  }\n",
    "  noise_var ~ inv_gamma(0.05, 0.05 * 0.01);\n",
    "  y ~ normal(tau + X * beta, sqrt(noise_var));\n",
    "}\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "mmm_posterior = stan.build(mmm_code,data=mmm_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_keqhy6qv/model_o3nw5otz.stan', line 51, column 35: assignment operator <- is deprecated in the Stan language; use = instead.\n",
      "Warning in '/tmp/httpstan_keqhy6qv/model_o3nw5otz.stan', line 53, column 16: assignment operator <- is deprecated in the Stan language; use = instead.\n",
      "Warning in '/tmp/httpstan_keqhy6qv/model_o3nw5otz.stan', line 54, column 34: assignment operator <- is deprecated in the Stan language; use = instead.\n",
      "Warning in '/tmp/httpstan_keqhy6qv/model_o3nw5otz.stan', line 56, column 4: assignment operator <- is deprecated in the Stan language; use = instead.Warning in '/tmp/httpstan_keqhy6qv/model_o3nw5otz.stan', line 66, column 30: Argument 0.0005 suggests there may be parameters that are not unit scale; consider rescaling with a multiplier (see manual section 22.12).\n",
      "Warning in '/tmp/httpstan_keqhy6qv/model_o3nw5otz.stan', line 66, column 24: Argument 0.05 suggests there may be parameters that are not unit scale; consider rescaling with a multiplier (see manual section 22.12).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "mmm_fit = mmm_posterior.sample(num_chains=3, num_samples=20)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Sampling:   0%\n",
      "Sampling:   0% (1/3600)\n",
      "Sampling:   0% (2/3600)\n",
      "Sampling:   0% (3/3600)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('mmm_venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "22f7b6250beb416fdc5cbe0cc3398fe4aac3ebb2dd05159e28f1ef5406b3f75c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}